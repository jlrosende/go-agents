model: openai.o3-mini

agents:
  agent_one:
    url: "http://localhost:8000/"

mcp:
  servers:
    filesystem:
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-filesystem", "."]
    fetch:
      command: "uvx"
      args: ["mcp-server-fetch"]

openai:
  # base_url: https://api.business.githubcopilot.com/
  base_url: https://api.githubcopilot.com/

azure:
  api_version: "2024-12-01-preview"
  azure_deployment: "o3-mini"

generic:
  api_key: ollama
  base_url: http://ollama:11434/v1
