
model: openai.o3-mini

agents:
  agent_one:
    url: "http://localhost:8000/"

mcp:
  servers:
    filesystem:
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-filesystem", "."]
    fetch:
      command: "uvx"
      args: ["mcp-server-fetch"]

openai:
  base_url: https://api.business.githubcopilot.com/

generic:
  api_key: ollama
  base_url: http://ollama:11434/v1