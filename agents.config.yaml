# model: &model generic.qwen3
# model: &model azure.o3-mini
# model: &model openai.o4-mini.high
model: &model azure.gpt-4.1.high

agents:
  agent_one:
    model: *model
    description: "agent to do thinkgs"
    instructions: |
      Follow these steps for each interaction:

      1. User Identification:
        - You should assume that you are interacting with default_user
        - If you have not identified default_user, proactively try to do so.

      2. Memory Retrieval:
        - Always begin your chat by saying only "Remembering..." and retrieve all relevant information from your knowledge graph
        - Always refer to your knowledge graph as your "memory"

      3. Memory
        - While conversing with the user, be attentive to any new information that falls into these categories:
          a) Basic Identity (age, gender, location, job title, education level, etc.)
          b) Behaviors (interests, habits, etc.)
          c) Preferences (communication style, preferred language, etc.)
          d) Goals (goals, targets, aspirations, etc.)
          e) Relationships (personal and professional relationships up to 3 degrees of separation)

      4. Memory Update:
        - If any new information was gathered during the interaction, update your memory as follows:
          a) Create entities for recurring organizations, people, and significant events
          b) Connect them to the current entities using relations
          b) Store facts about them as observations
    servers:
      - memory
      - filesystem
    exclude_tools:
      - read_graph
    request_params:
      parallel_tool_calls: false
      reasoning: false
      
mcp:
  servers:
    filesystem:
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-filesystem", "."]
    fetch:
      command: "uvx"
      args: ["mcp-server-fetch"]
    memory:
      command: "npx"
      args: ["-y", "@modelcontextprotocol/server-memory"]
      env:
        MEMORY_FILE_PATH: "/workspaces/go-agents/temp/memory/memory.json"
    # memory:
    #   command: "docker"
    #   args: ["run", "-i", "-v", "./temp/memory:/app/dist", "--rm", "mcp/memory"]
    # env:
    #   MEMORY_FILE_PATH: "./temp/memory/memory.json"

# openai:
#   base_url: https://api.business.githubcopilot.com/
# base_url: https://api.githubcopilot.com/
# base_url: https://api.openai.com/v1

azure:
  api_version: "2024-12-01-preview"

generic:
  api_key: ollama
  base_url: http://ollama:11434/v1/

logger:
  type: "console" # "console", "file"
  level: "debug" # "debug", "info", "warn", "error", "fatal"
  path: "agent.jsonl" # Path to log file (for "file" type)
